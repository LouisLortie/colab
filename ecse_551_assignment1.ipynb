{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LouisLortie/colab/blob/main/ecse_551_assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "cellView": "form",
        "id": "R45IlMgVGzOJ"
      },
      "outputs": [],
      "source": [
        "#@title Import list\n",
        "\n",
        "# from google.colab import drive                    # Need to activate this if using Google Colab (with drive)\n",
        "import csv\n",
        "import pandas as pd, numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12YlaNVrJK7Q",
        "outputId": "d9278b89-b691-44b1-a02a-3bef339f50d6"
      },
      "outputs": [],
      "source": [
        "#@title Load CSV\n",
        "\n",
        "# drive.mount('/content/drive')                    # Activate on drive\n",
        "# Reading air quality data\n",
        "# aq_csv = pd.read_csv(\"/content/drive/MyDrive/ecse_551/assignment1/air_quality.csv\")                 # Active on drive\n",
        "aq_csv = pd.read_csv(\"air_quality.csv\") \n",
        "\n",
        "# Reading liver patient data\n",
        "# lp_csv = pd.read_csv(\"/content/drive/MyDrive/ecse_551/assignment1/liver_patient.csv\")               # Active on drive\n",
        "lp_csv = pd.read_csv(\"liver_patient.csv\") \n",
        "\n",
        "# Array\n",
        "aq_data = np.array(aq_csv)\n",
        "lp_data = np.array(lp_csv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "LC017qoXbUnT"
      },
      "outputs": [],
      "source": [
        "#@title Setting rcParams\n",
        "plt.style.use('classic')\n",
        "plt.rcParams.update({\n",
        "                        #  \"text.usetex\": True,\n",
        "                        #  \"font.family\": \"serif\",\n",
        "                        #  \"font.sans-serif\": [\"Times\"],\n",
        "                         \"lines.linewidth\" : 3,\n",
        "                         \"font.size\" : 12,\n",
        "                         \"figure.constrained_layout.use\" : True,\n",
        "                         \"hist.bins\" : 100 \n",
        "                         })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "q2qkHNdRjq4Q"
      },
      "outputs": [],
      "source": [
        "#@title feature_count: Function that counts the number of features\n",
        "def feature_count(data):\n",
        "  return data.shape[1] - 1         # The last column is the class label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "z5wYo7KRgHVr"
      },
      "outputs": [],
      "source": [
        "#@title data_separation: Function that separates the training data into the two binary classes\n",
        "def data_separation(data):\n",
        "\n",
        "  count_pos = 0\n",
        "  count_neg = 0\n",
        "  \n",
        "  for i in range(data.shape[0]) :      # all rows of data\n",
        "\n",
        "    if data[i, -1] == 0 :\n",
        "      if count_neg == 0 :\n",
        "        data_neg = data[[i], :]\n",
        "      else :\n",
        "        data_neg = np.concatenate((data_neg, data[[i], :]), axis=0)\n",
        "      count_neg += 1\n",
        "\n",
        "    elif data[i, -1] == 1 :\n",
        "      if count_pos == 0 :\n",
        "        data_pos = data[[i], :]\n",
        "      else :\n",
        "        data_pos = np.concatenate((data_pos, data[[i], :]), axis=0)\n",
        "      count_pos += 1\n",
        "\n",
        "  return data_pos, data_neg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Generativelearning class: Generative model for binary classification\n",
        "\n",
        "class DiscriminativeLearning2:\n",
        "\n",
        "  def __init__(self, data):\n",
        "    self.data = data\n",
        "    self.data_pos, self.data_neg = data_separation(data)\n",
        "    self.feat_count = feature_count(self.data)\n",
        "    self.pos_count = self.data_pos.shape[0]\n",
        "    self.neg_count = self.data_neg.shape[0]\n",
        "    self.pos_prior = self.pos_count / self.data.shape[0]\n",
        "    self.neg_prior = self.neg_count / self.data.shape[0]\n",
        "    self.pos_mean = np.mean(self.data_pos[:,:-1], axis=0)\n",
        "    self.neg_mean = np.mean(self.data_neg[:,:-1], axis=0)\n",
        "\n",
        "    # Notice the difference in the covariance matrix calculation\n",
        "    self.cov = ((self.data_pos[:,:-1] - self.pos_mean).T @ (self.data_pos[:,:-1] - self.pos_mean) + (self.data_neg[:,:-1] - self.neg_mean).T @ (self.data_neg[:,:-1] - self.neg_mean)) / (self.pos_count + self.neg_count - 2)\n",
        "    self.cov_pos = (self.data_pos[:,:-1] - self.pos_mean).T @ (self.data_pos[:,:-1] - self.pos_mean) / (self.pos_count - 1)\n",
        "    self.cov_neg = (self.data_neg[:,:-1] - self.neg_mean).T @ (self.data_neg[:,:-1] - self.neg_mean) / (self.neg_count - 1)\n",
        "    \n",
        "\n",
        "  def fit_lda_linear(self):\n",
        "\n",
        "    self.w0 = np.log(self.pos_prior) - np.log(self.neg_prior) - 0.5 * self.pos_mean .T @ np.linalg.inv(self.cov) @ self.pos_mean + 0.5 * self.neg_mean .T @ np.linalg.inv(self.cov) @ self.neg_mean\n",
        "    self.w1 = np.linalg.inv(self.cov) @ (self.pos_mean - self.neg_mean)\n",
        "    self.w = np.concatenate((self.w0.reshape(1,), self.w1))\n",
        "\n",
        "    return self.w\n",
        "\n",
        "\n",
        "  def fit_lda_quadratic(self):      # Should be fine, but has not been tested out\n",
        "      \n",
        "      self.w0 = np.log(self.pos_prior) - np.log(self.neg_prior) - 0.5 * self.pos_mean .T @ np.linalg.inv(self.cov_pos) @ self.pos_mean + 0.5 * self.neg_mean .T @ np.linalg.inv(self.cov_neg) @ self.neg_mean - 0.5 * np.log(np.linalg.det(self.cov_pos)) + 0.5 * np.log(np.linalg.det(self.cov_neg))\n",
        "      self.w1 = np.linalg.inv(self.cov_pos) @ self.pos_mean - np.linalg.inv(self.cov_neg) @ self.neg_mean\n",
        "      self.w2 = -0.5 * np.linalg.inv(self.cov_neg) + 0.5 * np.linalg.inv(self.cov_pos)\n",
        "      self.w = np.concatenate((self.w0.reshape(1,), self.w1, self.w2))\n",
        "  \n",
        "      return self.w\n",
        "  \n",
        "\n",
        "\n",
        "  def predict(self, x):\n",
        "\n",
        "    self.y = x @ self.w[1:] + self.w[0]\n",
        "    \n",
        "    return self.y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title augment_ones function: Function that augments the data with a column of ones\n",
        "def augment_ones(data):\n",
        "    ones = np.ones((data.shape[0], 1))\n",
        "    return np.concatenate((data, ones), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title increase_complexity function: Function that increases the complexity of the data\n",
        "def increase_complexity(data):\n",
        "    # data = augment_ones(data)                                    # could be used to augment the data with a column of ones\n",
        "    data = np.concatenate((data, data[:, :-1]**2), axis=1)         # Here, we augment the data with a column of squares of the features\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "sKXJZHjFtRaL"
      },
      "outputs": [],
      "source": [
        "#@title plot hist: Function that plots the histogram of one feature\n",
        "# The number of bins can be changed via rcParams above.\n",
        "\n",
        "def plot_hist(feat_pos, feat_neg, feat_num):\n",
        "  fig, ax = plt.subplots(2, 1, sharex=True)\n",
        "  ax[0].hist(feat_pos, color=\"b\", label=r\"Class y = 1\")\n",
        "  ax[1].hist(feat_neg, color=\"r\", label=r\"Class y = 0\")\n",
        "  ax[0].set_title(\"Feature %i distribution comparison between classes\" %(feat_num + 1))\n",
        "  ax[0].legend(loc='upper right')\n",
        "  ax[1].legend(loc='upper right')\n",
        "  plt.tight_layout\n",
        "\n",
        "  return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title plot_regression: Function that plots the regression line\n",
        "\n",
        "def plot_regression(x, y, w, feature_num):    # Where x is the domain to which the regression line is to be plotted and i the feature number\n",
        "    \n",
        "    range = np.arange(np.min(x), np.max(x), 1/y.shape[0])\n",
        "    \n",
        "    fig, ax = plt.subplots(1, 1)\n",
        "    ax.scatter(x, y, color=\"b\", label=r\"Prediction\")\n",
        "    ax.plot(range, w[feature_num+1] * range + w[0], color=\"r\", label=r\"Regression line\")    # Because w[0] is the bias term\n",
        "    ax.set_title(\"Feature %i regression\" %(feature_num + 1))\n",
        "    ax.legend(loc='upper right')\n",
        "    plt.tight_layout\n",
        "    \n",
        "    return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title fold_prep: Separates data into testing, validation and testing sets\n",
        "def fold_prep(data, train_num, validation_num, test_num):\n",
        "    # np.random.shuffle(data)\n",
        "    data_train = data[:train_num, :]\n",
        "    data_val = data[train_num:train_num+validation_num, :]\n",
        "    data_test = data[train_num+validation_num:train_num+validation_num+test_num, :]\n",
        "    return data_train, data_val, data_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "id": "kZTP0QN_ic3l",
        "outputId": "4586a356-0e3b-4fb2-dc0d-4c48796b150a"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'DiscriminativeLearning2' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [174], line 17\u001b[0m\n\u001b[1;32m     12\u001b[0m   plot_regression(model2\u001b[38;5;241m.\u001b[39mdata[:,feat], model2\u001b[38;5;241m.\u001b[39my, model2\u001b[38;5;241m.\u001b[39mw, feat)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 17\u001b[0m     main()\n",
            "Cell \u001b[0;32mIn [174], line 8\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m feat \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m   \u001b[38;5;66;03m# Feature to analyse starting from 0\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# plot_hist(data_pos[:, feat], data_neg[:, feat], feat)\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m model2 \u001b[38;5;241m=\u001b[39m \u001b[43mDiscriminativeLearning2\u001b[49m(aq_data)\n\u001b[1;32m     10\u001b[0m w \u001b[38;5;241m=\u001b[39m model2\u001b[38;5;241m.\u001b[39mfit_lda_linear()\n\u001b[1;32m     11\u001b[0m model2\u001b[38;5;241m.\u001b[39mpredict(aq_data[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
            "\u001b[0;31mNameError\u001b[0m: name 'DiscriminativeLearning2' is not defined"
          ]
        }
      ],
      "source": [
        "#@title Main function\n",
        "def main():\n",
        "\n",
        "  feat = 3   # Feature to analyse starting from 0\n",
        "  \n",
        "  # plot_hist(data_pos[:, feat], data_neg[:, feat], feat)\n",
        "  \n",
        "  model2 = DiscriminativeLearning2(aq_data)\n",
        "  \n",
        "  w = model2.fit_lda_linear()\n",
        "  model2.predict(aq_data[:, :-1])\n",
        "  plot_regression(model2.data[:,feat], model2.y, model2.w, feat)\n",
        "\n",
        "  \n",
        "  \n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
