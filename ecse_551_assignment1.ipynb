{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LouisLortie/colab/blob/main/ecse_551_assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "cellView": "form",
        "id": "R45IlMgVGzOJ"
      },
      "outputs": [],
      "source": [
        "#@title Import list\n",
        "\n",
        "# from google.colab import drive                    # Need to activate this if using Google Colab (with drive)\n",
        "import csv\n",
        "import pandas as pd, numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12YlaNVrJK7Q",
        "outputId": "d9278b89-b691-44b1-a02a-3bef339f50d6"
      },
      "outputs": [],
      "source": [
        "#@title Load CSV\n",
        "\n",
        "# drive.mount('/content/drive')                    # Activate on drive\n",
        "# Reading air quality data\n",
        "# aq_csv = pd.read_csv(\"/content/drive/MyDrive/ecse_551/assignment1/air_quality.csv\")                 # Active on drive\n",
        "aq_csv = pd.read_csv(\"air_quality.csv\") \n",
        "\n",
        "# Reading liver patient data\n",
        "# lp_csv = pd.read_csv(\"/content/drive/MyDrive/ecse_551/assignment1/liver_patient.csv\")               # Active on drive\n",
        "lp_csv = pd.read_csv(\"liver_patient.csv\") \n",
        "\n",
        "# Array\n",
        "aq_data = np.array(aq_csv)\n",
        "lp_data = np.array(lp_csv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "LC017qoXbUnT"
      },
      "outputs": [],
      "source": [
        "#@title Setting rcParams\n",
        "plt.style.use('classic')\n",
        "plt.rcParams.update({\n",
        "                        #  \"text.usetex\": True,\n",
        "                        #  \"font.family\": \"serif\",\n",
        "                        #  \"font.sans-serif\": [\"Times\"],\n",
        "                         \"lines.linewidth\" : 3,\n",
        "                         \"font.size\" : 12,\n",
        "                         \"figure.constrained_layout.use\" : True,\n",
        "                         \"hist.bins\" : 100 \n",
        "                         })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "q2qkHNdRjq4Q"
      },
      "outputs": [],
      "source": [
        "#@title feature_count: Function that counts the number of features\n",
        "def feature_count(data):\n",
        "  return data.shape[1] - 1         # The last column is the class label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "z5wYo7KRgHVr"
      },
      "outputs": [],
      "source": [
        "#@title data_separation: Function that separates the training data into the two binary classes\n",
        "def data_separation(data):\n",
        "\n",
        "  count_pos = 0\n",
        "  count_neg = 0\n",
        "  \n",
        "  for i in range(data.shape[0]) :      # all rows of data\n",
        "\n",
        "    if data[i, -1] == 0 :\n",
        "      if count_neg == 0 :\n",
        "        data_neg = data[[i], :]\n",
        "      else :\n",
        "        data_neg = np.concatenate((data_neg, data[[i], :]), axis=0)\n",
        "      count_neg += 1\n",
        "\n",
        "    elif data[i, -1] == 1 :\n",
        "      if count_pos == 0 :\n",
        "        data_pos = data[[i], :]\n",
        "      else :\n",
        "        data_pos = np.concatenate((data_pos, data[[i], :]), axis=0)\n",
        "      count_pos += 1\n",
        "\n",
        "  return data_pos, data_neg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Generativelearning class: Generative model for binary classification\n",
        "\n",
        "class GenerativeLearning:\n",
        "\n",
        "  def __init__(self, data):\n",
        "    self.data = data\n",
        "    self.data_pos, self.data_neg = data_separation(data)\n",
        "    self.feat_count = feature_count(self.data)\n",
        "    self.pos_count = self.data_pos.shape[0]\n",
        "    self.neg_count = self.data_neg.shape[0]\n",
        "    self.pos_prior = self.pos_count / self.data.shape[0]\n",
        "    self.neg_prior = self.neg_count / self.data.shape[0]\n",
        "    self.pos_mean = np.mean(self.data_pos[:,:-1], axis=0)\n",
        "    self.neg_mean = np.mean(self.data_neg[:,:-1], axis=0)\n",
        "    # self.pos_cov = np.cov(self.data_pos, rowvar=False)\n",
        "    # self.neg_cov = np.cov(self.data_neg, rowvar=False)\n",
        "    print(self.data_pos[:,:-1].shape, \"\\n\")\n",
        "    print(self.pos_mean.shape, \"\\n\")\n",
        "    print(self.data_neg[:,:-1].shape, \"\\n\")\n",
        "    print((self.data_pos[:,:-1] - self.pos_mean).shape, \"\\n\")\n",
        "    self.cov = ((self.data_pos[:,:-1] - self.pos_mean).T @ (self.data_pos[:,:-1] - self.pos_mean) + (self.data_neg[:,:-1] - self.neg_mean).T @ (self.data_neg[:,:-1] - self.neg_mean)) / (self.pos_count + self.neg_count - 2)\n",
        "\n",
        "#   def discriminant(self, x, y):\n",
        "#     return np.log(self.pos_prior) - np.log(self.neg_prior) + 0.5 * (x - y).T @ np.linalg.inv(self.pos_cov - self.neg_cov) @ (x - y)\n",
        "  \n",
        "  # def covariance_common(self):\n",
        "\n",
        "  #   # Need to add dummy feature to data\n",
        "  #   # self.data_pos = np.concatenate((self.data_pos, np.ones((self.pos_count, 1))), axis=1)\n",
        "  #   # self.data_neg = np.concatenate((self.data_neg, np.ones((self.neg_count, 1))), axis=1)\n",
        "\n",
        "  #   self.cov = ((self.data_pos - self.pos_mean).T @ (self.data_pos - self.pos_mean) + (self.data_neg - self.neg_mean).T @ (self.data_neg - self.neg_mean)) / (self.pos_count + self.neg_count - 2)  # remove last bracket and check copilot suggestion\n",
        "  #   # Can we use np.linalg.inv()? Built in function and not effective.\n",
        "    \n",
        "  #   return \n",
        "\n",
        "#   def predict(self, x):\n",
        "#     return self.discriminant(x, self.pos_mean) - self.discriminant(x, self.neg_mean)\n",
        "\n",
        "  def fit(self):\n",
        "    self.w0 = np.log(self.pos_prior) - np.log(self.neg_prior) - 0.5 * self.pos_mean .T @ np.linalg.inv(self.cov) @ self.pos_mean + 0.5 * self.neg_mean .T @ np.linalg.inv(self.cov) @ self.neg_mean\n",
        "    self.w1 = np.linalg.inv(self.cov) @ (self.pos_mean - self.neg_mean)\n",
        "    self.w = np.concatenate((self.w0.reshape(1,), self.w1))\n",
        "    \n",
        "    return self.w\n",
        "\n",
        "  def predict(self, x):\n",
        "    self.y = x @ self.w[1:] + self.w[0]\n",
        "    return self.y\n",
        "\n",
        "#   def plot(self):\n",
        "#     fig, ax = plt.subplots(1, 1)\n",
        "#     ax.scatter(self.data_pos[:, 0], self.data_pos[:, 1], color=\"b\", label=r\"Class y = 1\")\n",
        "#     ax.scatter(self.data_neg[:, 0], self.data_neg[:, 1], color=\"r\", label=r\"Class y = 0\")\n",
        "#     ax.set_title(\"Feature %i distribution comparison between classes\" %(feat_num + 1))\n",
        "#     ax.legend(loc='upper right')\n",
        "#     plt.tight_layout\n",
        "\n",
        "    return 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "sKXJZHjFtRaL"
      },
      "outputs": [],
      "source": [
        "#@title plot hist: Function that plots the histogram of one feature\n",
        "# The number of bins can be changed via rcParams above.\n",
        "\n",
        "def plot_hist(feat_pos, feat_neg, feat_num):\n",
        "  fig, ax = plt.subplots(2, 1, sharex=True)\n",
        "  ax[0].hist(feat_pos, color=\"b\", label=r\"Class y = 1\")\n",
        "  ax[1].hist(feat_neg, color=\"r\", label=r\"Class y = 0\")\n",
        "  ax[0].set_title(\"Feature %i distribution comparison between classes\" %(feat_num + 1))\n",
        "  ax[0].legend(loc='upper right')\n",
        "  ax[1].legend(loc='upper right')\n",
        "  plt.tight_layout\n",
        "\n",
        "  return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title plot_regression: Function that plots the regression line\n",
        "\n",
        "def plot_regression(x, y, w, feature_num):    # Where x is the domain to which the regression line is to be plotted and i the feature number\n",
        "    \n",
        "    range = np.arange(np.min(x), np.max(x), 1/y.shape[0])\n",
        "    \n",
        "    fig, ax = plt.subplots(1, 1)\n",
        "    ax.scatter(x, y, color=\"b\", label=r\"Prediction\")\n",
        "    ax.plot(range, w[feature_num+1] * range + w[0], color=\"r\", label=r\"Regression line\")    # Because w[0] is the bias term\n",
        "    ax.set_title(\"Feature %i regression\" %(feature_num + 1))\n",
        "    ax.legend(loc='upper right')\n",
        "    plt.tight_layout\n",
        "    \n",
        "    return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title fold_prep: Separates data into testing, validation and testing sets\n",
        "def fold_prep(data, train_num, validation_num, test_num):\n",
        "    # np.random.shuffle(data)\n",
        "    data_train = data[:train_num, :]\n",
        "    data_val = data[train_num:train_num+validation_num, :]\n",
        "    data_test = data[train_num+validation_num:train_num+validation_num+test_num, :]\n",
        "    return data_train, data_val, data_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "id": "kZTP0QN_ic3l",
        "outputId": "4586a356-0e3b-4fb2-dc0d-4c48796b150a"
      },
      "outputs": [],
      "source": [
        "#@title Main function\n",
        "def main():\n",
        "\n",
        "  feat = 3   # Feature to analyse starting from 0\n",
        "  \n",
        "  # plot_hist(data_pos[:, feat], data_neg[:, feat], feat)\n",
        "  \n",
        "  model2 = GenerativeLearning(aq_data)\n",
        "\n",
        "  plot_regression(model2.data[:,feat], model2.y, model2.w, feat)\n",
        "\n",
        "  \n",
        "  \n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
