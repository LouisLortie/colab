{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LouisLortie/colab/blob/main/ecse_551_assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "R45IlMgVGzOJ"
      },
      "outputs": [],
      "source": [
        "#@title Import list\n",
        "\n",
        "# from google.colab import drive                    # Need to activate this if using Google Colab (with drive)\n",
        "import csv\n",
        "import pandas as pd, numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "q2qkHNdRjq4Q"
      },
      "outputs": [],
      "source": [
        "# Function that counts the number of features\n",
        "def feature_count(data):\n",
        "  return data.shape[1] - 1         # The last column is the class label\n",
        "\n",
        "# Function that separates the input and output data\n",
        "def get_xy_data(data):\n",
        "    x = data[:,:-1]\n",
        "    y = data[:,-1].reshape(-1,1)\n",
        "    return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "z5wYo7KRgHVr"
      },
      "outputs": [],
      "source": [
        "# Function that classifies the training data into the two binary classes\n",
        "def data_separation(data):\n",
        "\n",
        "  count_class1 = 0\n",
        "  count_class0 = 0\n",
        "  \n",
        "  for i in range(data.shape[0]) :      # all rows of data\n",
        "\n",
        "    if data[i, -1] == 0 :\n",
        "      if count_class0== 0 :\n",
        "        data_class0 = data[[i], :]\n",
        "      else :\n",
        "        data_class0 = np.concatenate((data_class0, data[[i], :]), axis=0)\n",
        "      count_class0+= 1\n",
        "\n",
        "    elif data[i, -1] == 1 :\n",
        "      if count_class1 == 0 :\n",
        "        data_class1 = data[[i], :]\n",
        "      else :\n",
        "        data_class1 = np.concatenate((data_class1, data[[i], :]), axis=0)\n",
        "      count_class1 += 1\n",
        "\n",
        "  return data_class1, data_class0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12YlaNVrJK7Q",
        "outputId": "d9278b89-b691-44b1-a02a-3bef339f50d6"
      },
      "outputs": [],
      "source": [
        "#@title Load CSV\n",
        "\n",
        "# drive.mount('/content/drive')                    # Activate on drive\n",
        "# Reading air quality data\n",
        "# aq_csv = pd.read_csv(\"/content/drive/MyDrive/ecse_551/assignment1/air_quality.csv\")                 # Active on drive\n",
        "aq_csv = pd.read_csv(\"air_quality.csv\") \n",
        "\n",
        "# Reading liver patient data\n",
        "# lp_csv = pd.read_csv(\"/content/drive/MyDrive/ecse_551/assignment1/liver_patient.csv\")               # Active on drive\n",
        "lp_csv = pd.read_csv(\"liver_patient.csv\") \n",
        "\n",
        "# Array\n",
        "aq_data = np.array(aq_csv)\n",
        "lp_data = np.array(lp_csv)\n",
        "\n",
        "# Divide into inputs and outputs\n",
        "aq_x, aq_y = get_xy_data(aq_data)\n",
        "lp_x, lp_y = get_xy_data(lp_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LC017qoXbUnT"
      },
      "outputs": [],
      "source": [
        "#@title Setting rcParams\n",
        "plt.style.use('classic')\n",
        "plt.rcParams.update({\n",
        "                        #  \"text.usetex\": True,\n",
        "                        #  \"font.family\": \"serif\",\n",
        "                        #  \"font.sans-serif\": [\"Times\"],\n",
        "                         \"lines.linewidth\" : 3,\n",
        "                         \"font.size\" : 12,\n",
        "                         \"figure.constrained_layout.use\" : True,\n",
        "                         \"hist.bins\" : 100 \n",
        "                         })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Machine learning method: Classicifiation Discriminative learning\n",
        "class DiscriminativeLearning():\n",
        "\n",
        "    def __init__(self, x, y, step_size, epsilon):\n",
        "        self.x = np.insert(x, 0, 1, axis=1)\n",
        "        self.y = y\n",
        "        self.step_size = step_size\n",
        "        self.epsilon = epsilon\n",
        "        self.w0 = np.zeros((self.x.shape[1], 1))\n",
        "    \n",
        "    def logistic_function(self, w, xi):\n",
        "        a = w.T @ xi\n",
        "        s = 1 / (1 + np.exp(-a))\n",
        "        return s\n",
        "\n",
        "    def fit(self):\n",
        "        delta = 0\n",
        "        w_old = self.w0\n",
        "        w_new = w_old\n",
        "        while True:\n",
        "            w_old = w_new\n",
        "            for i in range(self.x.shape[0]):\n",
        "                xi = self.x[i].reshape(-1,1)\n",
        "                yi = self.y[i]\n",
        "                delta = delta - xi @ (yi - self.logistic_function(w_old, xi))\n",
        "            w_new = w_old - self.step_size * delta\n",
        "            error = np.linalg.norm(w_new - w_old, ord =2)\n",
        "            if error < self.epsilon:\n",
        "                break\n",
        "        return w_new\n",
        "\n",
        "    def predict(self, w, x):\n",
        "        x = np.insert(x, 0, 1, axis=1)\n",
        "        p = w.T @ x\n",
        "        if p > 0.5:\n",
        "            y = 1\n",
        "        elif p == 0.5:\n",
        "            # randomly choose 0 or 1\n",
        "            y = np.random.randint(0,2)\n",
        "        else:\n",
        "            y = 0\n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title class_separation function: Separate the data into two classes\n",
        "def class_separation(data):\n",
        "\n",
        "  count_class0 = 0\n",
        "  count_class1 = 0\n",
        "\n",
        "  for i in range(data.shape[0]):\n",
        "\n",
        "    if data[i, -1] == 0 :\n",
        "      if count_class0 == 0 :\n",
        "        data_class0 = data[[i], :]\n",
        "      else :\n",
        "        data_class0 = np.concatenate((data_class0, data[[i], :]), axis=0)\n",
        "      count_class0 += 1\n",
        "\n",
        "    elif data[i, -1] == 1 :\n",
        "      if count_class1 == 0 :\n",
        "        data_class1 = data[[i], :]\n",
        "      else :\n",
        "        data_class1 = np.concatenate((data_class1, data[[i], :]), axis=0)\n",
        "      count_class1 += 1\n",
        "\n",
        "      return data_class1, data_class0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title GenerativeLearning class: Generative model for binary classification\n",
        "\n",
        "class GenerativeLearning:\n",
        "\n",
        "  def __init__(self, data):\n",
        "    self.data = data\n",
        "    self.data_class1, self.data_class0 = data_separation(data)\n",
        "    self.feat_count = feature_count(self.data)\n",
        "    self.class1_count = self.data_class1.shape[0]\n",
        "    self.class0_count = self.data_class0.shape[0]\n",
        "    self.class1_prior = self.class1_count / self.data.shape[0]\n",
        "    self.class0_prior = self.class0_count / self.data.shape[0]\n",
        "    self.class1_mean = np.mean(self.data_class1[:,:-1], axis=0)\n",
        "    self.class0_mean = np.mean(self.data_class0[:,:-1], axis=0)\n",
        "\n",
        "    # Notice the difference in the covariance matrix calculation\n",
        "    self.cov = ((self.data_class1[:,:-1] - self.class1_mean).T @ (self.data_class1[:,:-1] - self.class1_mean) + (self.data_class0[:,:-1] - self.class0_mean).T @ (self.data_class0[:,:-1] - self.class0_mean)) / (self.class1_count + self.class0_count - 2)\n",
        "    self.cov_class1 = (self.data_class1[:,:-1] - self.class1_mean).T @ (self.data_class1[:,:-1] - self.class1_mean) / (self.class1_count - 1)\n",
        "    self.cov_class0 = (self.data_class0[:,:-1] - self.class0_mean).T @ (self.data_class0[:,:-1] - self.class0_mean) / (self.class0_count - 1)\n",
        "    \n",
        "\n",
        "  def fit_lda_linear(self):\n",
        "\n",
        "    self.w0 = np.log(self.class1_prior) - np.log(self.class0_prior) - 0.5 * self.class1_mean .T @ np.linalg.inv(self.cov) @ self.class1_mean + 0.5 * self.class0_mean .T @ np.linalg.inv(self.cov) @ self.class0_mean\n",
        "    self.w1 = np.linalg.inv(self.cov) @ (self.class1_mean - self.class0_mean)\n",
        "    self.w = np.concatenate((self.w0.reshape(1,), self.w1))\n",
        "\n",
        "    return self.w\n",
        "\n",
        "\n",
        "  def fit_qda_linear(self):      # Should be fine, but has not been tested out\n",
        "      \n",
        "      self.w0 = np.log(self.class1_prior) - np.log(self.class0_prior) - 0.5 * self.class1_mean .T @ np.linalg.inv(self.cov_class1) @ self.class1_mean + 0.5 * self.class0_mean .T @ np.linalg.inv(self.cov_class0) @ self.class0_mean - 0.5 * np.log(np.linalg.det(self.cov_class1)) + 0.5 * np.log(np.linalg.det(self.cov_class0))\n",
        "      self.w1 = np.linalg.inv(self.cov_class1) @ self.class1_mean - np.linalg.inv(self.cov_class0) @ self.class0_mean\n",
        "      self.w2 = -0.5 * np.linalg.inv(self.cov_class0) + 0.5 * np.linalg.inv(self.cov_class1)\n",
        "      self.w = np.concatenate((self.w0.reshape(1,), self.w1, self.w2))\n",
        "  \n",
        "      return self.w\n",
        "\n",
        "\n",
        "  def predict(self, x):\n",
        "\n",
        "    self.y = x @ self.w[1:] + self.w[0]\n",
        "    # print(self.y)\n",
        "    \n",
        "    return self.y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title augment_ones function: Function that augments the data with a column of ones\n",
        "def augment_ones(data):\n",
        "    ones = np.ones((data.shape[0], 1))\n",
        "    return np.concatenate((data, ones), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title increase_complexity function: Function that increases the complexity of the data\n",
        "\n",
        "def increase_complexity(data, feat_num):\n",
        "    # data = augment_ones(data)                                    # could be used to augment the data with a column of ones\n",
        "\n",
        "    last_col = data[:, [-1]]\n",
        "    data = data[:, :-1]\n",
        "\n",
        "    for i in range(feat_num.shape[0]):\n",
        "        data = np.concatenate((data, data[:, [feat_num[i]]]**2), axis=1)   # augment the matrix by adding a column of the square of the feature\n",
        "\n",
        "    data = np.concatenate((data, last_col), axis=1)       # add the last column back to the matrix\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title fold_prep: Separates data into testing, validation and testing sets\n",
        "def fold_prep(data, train_num, validation_num, test_num):\n",
        "    # np.random.shuffle(data)\n",
        "    data_train = data[:train_num, :]\n",
        "    data_val = data[train_num:train_num+validation_num, :]\n",
        "    data_test = data[train_num+validation_num:train_num+validation_num+test_num, :]\n",
        "    return data_train, data_val, data_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "sKXJZHjFtRaL"
      },
      "outputs": [],
      "source": [
        "#@title plot hist: Function that plots the histogram of one feature\n",
        "# The number of bins can be changed via rcParams above.\n",
        "\n",
        "def plot_hist(feat_class1, feat_class0, feat_num):\n",
        "  fig, ax = plt.subplots(2, 1, sharex=True)\n",
        "  ax[0].hist(feat_class1, color=\"b\", label=r\"Class y = 1\")\n",
        "  ax[1].hist(feat_class0, color=\"r\", label=r\"Class y = 0\")\n",
        "  ax[0].set_title(\"Feature %i distribution comparison between classes\" %(feat_num + 1))\n",
        "  ax[0].legend(loc='upper right')\n",
        "  ax[1].legend(loc='upper right')\n",
        "  plt.tight_layout\n",
        "\n",
        "  return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title prediction_line: Function that plots the regression line\n",
        "\n",
        "# Cannot plot the regression because there are too many features. Would be fine with 2 features.\n",
        "\n",
        "# This plot shows that if its above zero, it is classified as 1, and if its below zero, it is classified as 0.\n",
        "\n",
        "def prediction_line(x_class1, x_class0, w): \n",
        "\n",
        "    count_false1 = 0\n",
        "    count_false0 = 0\n",
        "    \n",
        "    x = (np.concatenate((x_class1, x_class0), axis=0)).reshape(-1, 1)\n",
        "    \n",
        "    fig, ax = plt.subplots(1, 1)\n",
        "    y_class1 = x_class1 @ w[1:] + w[0]\n",
        "    y_class0 = x_class0 @ w[1:] + w[0]\n",
        "    range1 = np.linspace(np.min(x), np.max(x), y_class1.shape[0])\n",
        "    range2 = np.linspace(np.min(x), np.max(x), y_class0.shape[0])\n",
        "\n",
        "    for i in range(y_class1.shape[0]):\n",
        "        if y_class1[i] < 0:\n",
        "            count_false1 += 1\n",
        "\n",
        "    for i in range(y_class0.shape[0]):\n",
        "        if y_class0[i] > 0:\n",
        "            count_false0 += 1\n",
        "\n",
        "    print(\"Number of false positives: %i\" %(count_false1))\n",
        "    print(\"Number of false negatives: %i\" %(count_false0))\n",
        "    print(\"Total of class1: %i\" %(y_class1.shape[0]))\n",
        "    print(\"Total of class0: %i\" %(y_class0.shape[0]))\n",
        "\n",
        "    ax.scatter(range1, y_class1, color=\"b\", label=r\"Class y = 1\")\n",
        "    ax.scatter(range2, y_class0, color=\"r\", label=r\"Class y = 0\")\n",
        "    ax.plot([np.min(x), np.max(x)], [0, 0], color=\"g\")\n",
        "    ax.set_title(\"Predictions\")\n",
        "    ax.legend(loc='upper right')\n",
        "    plt.tight_layout\n",
        "    \n",
        "    return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "id": "kZTP0QN_ic3l",
        "outputId": "4586a356-0e3b-4fb2-dc0d-4c48796b150a"
      },
      "outputs": [
        {
          "ename": "UnboundLocalError",
          "evalue": "local variable 'aq_data' referenced before assignment",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [64], line 37\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[39m# Divide into inputs and outputs\u001b[39;00m\n\u001b[1;32m     18\u001b[0m   \u001b[39m# aq_x, aq_y = get_xy_data(aq_data)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m   \u001b[39m# lp_x, lp_y = get_xy_data(lp_data)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m   \u001b[39m# model2.predict(aq_data[:, :-1])\u001b[39;00m\n\u001b[1;32m     34\u001b[0m   \u001b[39m# prediction_line(data_class1[:, :-1], data_class0[:, :-1], model2.w)\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m---> 37\u001b[0m     main()\n",
            "Cell \u001b[0;32mIn [64], line 6\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmain\u001b[39m():\n\u001b[1;32m      4\u001b[0m   feat \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m   \u001b[39m# Feature to analyse.\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m   aq_data_aug \u001b[39m=\u001b[39m increase_complexity(aq_data, np\u001b[39m.\u001b[39marray([\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m6\u001b[39m, \u001b[39m7\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m9\u001b[39m, \u001b[39m10\u001b[39m]))\n\u001b[1;32m      8\u001b[0m   aq_data \u001b[39m=\u001b[39m aq_data_aug\n\u001b[1;32m     10\u001b[0m   \u001b[39mprint\u001b[39m (aq_data\u001b[39m.\u001b[39mshape)\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'aq_data' referenced before assignment"
          ]
        }
      ],
      "source": [
        "#@title Main function\n",
        "def main():\n",
        "\n",
        "  feat = 0   # Feature to analyse.\n",
        "\n",
        "  aq_data_aug = increase_complexity(aq_data, np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]))\n",
        "\n",
        "  print (aq_data_aug.shape)\n",
        "  print(aq_data_aug)\n",
        "\n",
        "  data_class1, data_class0 = data_separation(aq_data_aug)\n",
        "  \n",
        "  plot_hist(data_class1[:, feat], data_class0[:, feat], feat)\n",
        "\n",
        "  # Divide into inputs and outputs\n",
        "  # aq_x, aq_y = get_xy_data(aq_data)\n",
        "  # lp_x, lp_y = get_xy_data(lp_data)\n",
        "  # # aq_dl = DiscriminativeLearning(aq_x, aq_y, 0.001, 0.01)\n",
        "  # lp_dl = DiscriminativeLearning(lp_x, lp_y, 0.001, 0.01)\n",
        "  # # w1 = aq_dl.fit()\n",
        "  # w2 = lp_dl.fit()\n",
        "  # print(w2)\n",
        "  \n",
        "  # plot_hist(data_class1[:,data_class0 feat], data_class0[:, feat], feat)\n",
        "  \n",
        "  model2 = GenerativeLearning(aq_data_aug)\n",
        "\n",
        "  # data_class1, data_class0 = data_separation(aq_data)\n",
        "  \n",
        "  w = model2.fit_qda_linear()\n",
        "  model2.predict(aq_data_aug[:, :-1])\n",
        "  prediction_line(data_class1[:, :-1], data_class0[:, :-1], model2.w)\n",
        "  \n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
