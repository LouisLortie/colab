{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LouisLortie/colab/blob/main/ecse_551_assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "cellView": "form",
        "id": "R45IlMgVGzOJ"
      },
      "outputs": [],
      "source": [
        "#@title Import list\n",
        "\n",
        "# from google.colab import drive                    # Need to activate this if using Google Colab (with drive)\n",
        "import csv\n",
        "import pandas as pd, numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "q2qkHNdRjq4Q"
      },
      "outputs": [],
      "source": [
        "# Function that counts the number of features\n",
        "def feature_count(data):\n",
        "  return data.shape[1] - 1         # The last column is the class label\n",
        "\n",
        "# Function that separates the input and output data\n",
        "def get_xy_data(data):\n",
        "    x = data[:,:-1]\n",
        "    y = data[:,-1].reshape(-1,1)\n",
        "    return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "z5wYo7KRgHVr"
      },
      "outputs": [],
      "source": [
        "# Function that classifies the training data into the two binary classes\n",
        "def data_separation(data):\n",
        "\n",
        "  count_pos = 0\n",
        "  count_neg = 0\n",
        "  \n",
        "  for i in range(data.shape[0]) :      # all rows of data\n",
        "\n",
        "    if data[i, -1] == 0 :\n",
        "      if count_neg == 0 :\n",
        "        data_neg = data[[i], :]\n",
        "      else :\n",
        "        data_neg = np.concatenate((data_neg, data[[i], :]), axis=0)\n",
        "      count_neg += 1\n",
        "\n",
        "    elif data[i, -1] == 1 :\n",
        "      if count_pos == 0 :\n",
        "        data_pos = data[[i], :]\n",
        "      else :\n",
        "        data_pos = np.concatenate((data_pos, data[[i], :]), axis=0)\n",
        "      count_pos += 1\n",
        "\n",
        "  return data_pos, data_neg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12YlaNVrJK7Q",
        "outputId": "d9278b89-b691-44b1-a02a-3bef339f50d6"
      },
      "outputs": [],
      "source": [
        "#@title Load CSV\n",
        "\n",
        "# drive.mount('/content/drive')                    # Activate on drive\n",
        "# Reading air quality data\n",
        "# aq_csv = pd.read_csv(\"/content/drive/MyDrive/ecse_551/assignment1/air_quality.csv\")                 # Active on drive\n",
        "aq_csv = pd.read_csv(\"air_quality.csv\") \n",
        "\n",
        "# Reading liver patient data\n",
        "# lp_csv = pd.read_csv(\"/content/drive/MyDrive/ecse_551/assignment1/liver_patient.csv\")               # Active on drive\n",
        "lp_csv = pd.read_csv(\"liver_patient.csv\") \n",
        "\n",
        "# Array\n",
        "aq_data = np.array(aq_csv)\n",
        "lp_data = np.array(lp_csv)\n",
        "\n",
        "# Divide into inputs and outputs\n",
        "aq_x, aq_y = get_xy_data(aq_data)\n",
        "lp_x, lp_y = get_xy_data(lp_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "LC017qoXbUnT"
      },
      "outputs": [],
      "source": [
        "#@title Setting rcParams\n",
        "plt.style.use('classic')\n",
        "plt.rcParams.update({\n",
        "                        #  \"text.usetex\": True,\n",
        "                        #  \"font.family\": \"serif\",\n",
        "                        #  \"font.sans-serif\": [\"Times\"],\n",
        "                         \"lines.linewidth\" : 3,\n",
        "                         \"font.size\" : 12,\n",
        "                         \"figure.constrained_layout.use\" : True,\n",
        "                         \"hist.bins\" : 100 \n",
        "                         })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Machine learning method: Classicifiation Discriminative learning\n",
        "class DiscriminativeLearning():\n",
        "\n",
        "    def __init__(self, x, y, step_size, epsilon):\n",
        "        self.x = np.insert(x, 0, 1, axis=1)\n",
        "        self.y = y\n",
        "        self.step_size = step_size\n",
        "        self.epsilon = epsilon\n",
        "        self.w0 = np.zeros((self.x.shape[1], 1))\n",
        "    \n",
        "    def logistic_function(self, w, xi):\n",
        "        a = w.T @ xi\n",
        "        s = 1 / (1 + np.exp(-a))\n",
        "        return s\n",
        "\n",
        "    def fit(self):\n",
        "        delta = 0\n",
        "        w_old = self.w0\n",
        "        w_new = w_old\n",
        "        while True:\n",
        "            w_old = w_new\n",
        "            for i in range(self.x.shape[0]):\n",
        "                xi = self.x[i].reshape(-1,1)\n",
        "                yi = self.y[i]\n",
        "                delta = delta - xi @ (yi - self.logistic_function(w_old, xi))\n",
        "            w_new = w_old - self.step_size * delta\n",
        "            error = np.linalg.norm(w_new - w_old, ord =2)\n",
        "            if error < self.epsilon:\n",
        "                break\n",
        "        return w_new\n",
        "\n",
        "    def predict(self, w, x):\n",
        "        x = np.insert(x, 0, 1, axis=1)\n",
        "        p = w.T @ x\n",
        "        if p > 0.5:\n",
        "            y = 1\n",
        "        elif p == 0.5:\n",
        "            # randomly choose 0 or 1\n",
        "            y = np.random.randint(0,2)\n",
        "        else:\n",
        "            y = 0\n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Generativelearning class: Generative model for binary classification\n",
        "\n",
        "class GenerativeLearning:\n",
        "\n",
        "  def __init__(self, data):\n",
        "    self.data = data\n",
        "    self.data_pos, self.data_neg = data_separation(data)\n",
        "    self.feat_count = feature_count(self.data)\n",
        "    self.pos_count = self.data_pos.shape[0]\n",
        "    self.neg_count = self.data_neg.shape[0]\n",
        "    self.pos_prior = self.pos_count / self.data.shape[0]\n",
        "    self.neg_prior = self.neg_count / self.data.shape[0]\n",
        "    self.pos_mean = np.mean(self.data_pos[:,:-1], axis=0)\n",
        "    self.neg_mean = np.mean(self.data_neg[:,:-1], axis=0)\n",
        "\n",
        "    # Notice the difference in the covariance matrix calculation\n",
        "    self.cov = ((self.data_pos[:,:-1] - self.pos_mean).T @ (self.data_pos[:,:-1] - self.pos_mean) + (self.data_neg[:,:-1] - self.neg_mean).T @ (self.data_neg[:,:-1] - self.neg_mean)) / (self.pos_count + self.neg_count - 2)\n",
        "    self.cov_pos = (self.data_pos[:,:-1] - self.pos_mean).T @ (self.data_pos[:,:-1] - self.pos_mean) / (self.pos_count - 1)\n",
        "    self.cov_neg = (self.data_neg[:,:-1] - self.neg_mean).T @ (self.data_neg[:,:-1] - self.neg_mean) / (self.neg_count - 1)\n",
        "    \n",
        "\n",
        "  def fit_lda_linear(self):\n",
        "\n",
        "    self.w0 = np.log(self.pos_prior) - np.log(self.neg_prior) - 0.5 * self.pos_mean .T @ np.linalg.inv(self.cov) @ self.pos_mean + 0.5 * self.neg_mean .T @ np.linalg.inv(self.cov) @ self.neg_mean\n",
        "    self.w1 = np.linalg.inv(self.cov) @ (self.pos_mean - self.neg_mean)\n",
        "    self.w = np.concatenate((self.w0.reshape(1,), self.w1))\n",
        "\n",
        "    return self.w\n",
        "\n",
        "\n",
        "  def fit_lda_quadratic(self):      # Should be fine, but has not been tested out\n",
        "      \n",
        "      self.w0 = np.log(self.pos_prior) - np.log(self.neg_prior) - 0.5 * self.pos_mean .T @ np.linalg.inv(self.cov_pos) @ self.pos_mean + 0.5 * self.neg_mean .T @ np.linalg.inv(self.cov_neg) @ self.neg_mean - 0.5 * np.log(np.linalg.det(self.cov_pos)) + 0.5 * np.log(np.linalg.det(self.cov_neg))\n",
        "      self.w1 = np.linalg.inv(self.cov_pos) @ self.pos_mean - np.linalg.inv(self.cov_neg) @ self.neg_mean\n",
        "      self.w2 = -0.5 * np.linalg.inv(self.cov_neg) + 0.5 * np.linalg.inv(self.cov_pos)\n",
        "      self.w = np.concatenate((self.w0.reshape(1,), self.w1, self.w2))\n",
        "  \n",
        "      return self.w\n",
        "  \n",
        "\n",
        "  if data[i, -1] == 0 :\n",
        "    if count_class0 == 0 :\n",
        "      data_class0 = data[[i], :]\n",
        "    else :\n",
        "      data_class0 = np.concatenate((data_class0, data[[i], :]), axis=0)\n",
        "    count_class0 += 1\n",
        "\n",
        "  elif data[i, -1] == 1 :\n",
        "    if count_class1 == 0 :\n",
        "      data_class1 = data[[i], :]\n",
        "    else :\n",
        "      data_class1 = np.concatenate((data_class1, data[[i], :]), axis=0)\n",
        "    count_class1 += 1\n",
        "\n",
        "  return data_class1, data_class0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title GenerativeLearning class: Generative model for binary classification\n",
        "\n",
        "class GenerativeLearning:\n",
        "\n",
        "  def __init__(self, data):\n",
        "    self.data = data\n",
        "    self.data_class1, self.data_class0 = data_separation(data)\n",
        "    self.feat_count = feature_count(self.data)\n",
        "    self.class1_count = self.data_class1.shape[0]\n",
        "    self.class0_count = self.data_class0.shape[0]\n",
        "    self.class1_prior = self.class1_count / self.data.shape[0]\n",
        "    self.class0_prior = self.class0_count / self.data.shape[0]\n",
        "    self.class1_mean = np.mean(self.data_class1[:,:-1], axis=0)\n",
        "    self.class0_mean = np.mean(self.data_class0[:,:-1], axis=0)\n",
        "\n",
        "    # Notice the difference in the covariance matrix calculation\n",
        "    self.cov = ((self.data_class1[:,:-1] - self.class1_mean).T @ (self.data_class1[:,:-1] - self.class1_mean) + (self.data_class0[:,:-1] - self.class0_mean).T @ (self.data_class0[:,:-1] - self.class0_mean)) / (self.class1_count + self.class0_count - 2)\n",
        "    self.cov_class1 = (self.data_class1[:,:-1] - self.class1_mean).T @ (self.data_class1[:,:-1] - self.class1_mean) / (self.class1_count - 1)\n",
        "    self.cov_class0 = (self.data_class0[:,:-1] - self.class0_mean).T @ (self.data_class0[:,:-1] - self.class0_mean) / (self.class0_count - 1)\n",
        "    \n",
        "\n",
        "  def fit_lda_linear(self):\n",
        "\n",
        "    self.w0 = np.log(self.class1_prior) - np.log(self.class0_prior) - 0.5 * self.class1_mean .T @ np.linalg.inv(self.cov) @ self.class1_mean + 0.5 * self.class0_mean .T @ np.linalg.inv(self.cov) @ self.class0_mean\n",
        "    self.w1 = np.linalg.inv(self.cov) @ (self.class1_mean - self.class0_mean)\n",
        "    self.w = np.concatenate((self.w0.reshape(1,), self.w1))\n",
        "\n",
        "    return self.w\n",
        "\n",
        "\n",
        "  def fit_lda_quadratic(self):      # Should be fine, but has not been tested out\n",
        "      \n",
        "      self.w0 = np.log(self.class1_prior) - np.log(self.class0_prior) - 0.5 * self.class1_mean .T @ np.linalg.inv(self.cov_class1) @ self.class1_mean + 0.5 * self.class0_mean .T @ np.linalg.inv(self.cov_class0) @ self.class0_mean - 0.5 * np.log(np.linalg.det(self.cov_class1)) + 0.5 * np.log(np.linalg.det(self.cov_class0))\n",
        "      self.w1 = np.linalg.inv(self.cov_class1) @ self.class1_mean - np.linalg.inv(self.cov_class0) @ self.class0_mean\n",
        "      self.w2 = -0.5 * np.linalg.inv(self.cov_class0) + 0.5 * np.linalg.inv(self.cov_class1)\n",
        "      self.w = np.concatenate((self.w0.reshape(1,), self.w1, self.w2))\n",
        "  \n",
        "      return self.w\n",
        "\n",
        "\n",
        "  def predict(self, x):\n",
        "\n",
        "    self.y = x @ self.w[1:] + self.w[0]\n",
        "    # print(self.y)\n",
        "    \n",
        "    return self.y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title augment_ones function: Function that augments the data with a column of ones\n",
        "def augment_ones(data):\n",
        "    ones = np.ones((data.shape[0], 1))\n",
        "    return np.concatenate((data, ones), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title increase_complexity function: Function that increases the complexity of the data\n",
        "\n",
        "def increase_complexity(data, feat_num):\n",
        "    # data = augment_ones(data)                                    # could be used to augment the data with a column of ones\n",
        "\n",
        "    for i in range(feat_num):\n",
        "        data = np.concatenate((data, data[:, feat_num[i]]** 2), axis=1)\n",
        "\n",
        "    data = np.concatenate((data, data[:, feat_num]**2), axis=1)         # Here, we augment the data with a column of squares of the features\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title fold_prep: Separates data into testing, validation and testing sets\n",
        "def fold_prep(data, train_num, validation_num, test_num):\n",
        "    # np.random.shuffle(data)\n",
        "    data_train = data[:train_num, :]\n",
        "    data_val = data[train_num:train_num+validation_num, :]\n",
        "    data_test = data[train_num+validation_num:train_num+validation_num+test_num, :]\n",
        "    return data_train, data_val, data_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "sKXJZHjFtRaL"
      },
      "outputs": [],
      "source": [
        "#@title plot hist: Function that plots the histogram of one feature\n",
        "# The number of bins can be changed via rcParams above.\n",
        "\n",
        "def plot_hist(feat_class1, feat_class0, feat_num):\n",
        "  fig, ax = plt.subplots(2, 1, sharex=True)\n",
        "  ax[0].hist(feat_class1, color=\"b\", label=r\"Class y = 1\")\n",
        "  ax[1].hist(feat_class0, color=\"r\", label=r\"Class y = 0\")\n",
        "  ax[0].set_title(\"Feature %i distribution comparison between classes\" %(feat_num + 1))\n",
        "  ax[0].legend(loc='upper right')\n",
        "  ax[1].legend(loc='upper right')\n",
        "  plt.tight_layout\n",
        "\n",
        "  return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title prediction_line: Function that plots the regression line\n",
        "\n",
        "# Cannot plot the regression because there are too many features. Would be fine with 2 features.\n",
        "\n",
        "# This plot shows that if its above zero, it is classified as 1, and if its below zero, it is classified as 0.\n",
        "\n",
        "def prediction_line(x_class1, x_class0, w): \n",
        "    \n",
        "    x = (np.concatenate((x_class1, x_class0), axis=0)).reshape(-1, 1)\n",
        "    \n",
        "    fig, ax = plt.subplots(1, 1)\n",
        "    y_class1 = x_class1 @ w[1:] + w[0]\n",
        "    y_class0 = x_class0 @ w[1:] + w[0]\n",
        "    range1 = np.linspace(np.min(x), np.max(x), y_class1.shape[0])\n",
        "    range2 = np.linspace(np.min(x), np.max(x), y_class0.shape[0])\n",
        "\n",
        "    ax.scatter(range1, y_class1, color=\"b\", label=r\"Class y = 1\")\n",
        "    ax.scatter(range2, y_class0, color=\"r\", label=r\"Class y = 0\")\n",
        "    ax.plot([np.min(x), np.max(x)], [0, 0], color=\"g\")\n",
        "    ax.set_title(\"Predictions\")\n",
        "    ax.legend(loc='upper right')\n",
        "    plt.tight_layout\n",
        "    \n",
        "    return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "id": "kZTP0QN_ic3l",
        "outputId": "4586a356-0e3b-4fb2-dc0d-4c48796b150a"
      },
      "outputs": [],
      "source": [
        "#@title Main function\n",
        "def main():\n",
        "\n",
        "  feat = 9   # Feature to analyse.\n",
        "\n",
        "  data_pos, data_neg = data_separation(aq_data)\n",
        "  \n",
        "  plot_hist(data_pos[:, feat], data_neg[:, feat], feat)\n",
        "\n",
        "  # Divide into inputs and outputs\n",
        "  aq_x, aq_y = get_xy_data(aq_data)\n",
        "  lp_x, lp_y = get_xy_data(lp_data)\n",
        "  # aq_dl = DiscriminativeLearning(aq_x, aq_y, 0.001, 0.01)\n",
        "  lp_dl = DiscriminativeLearning(lp_x, lp_y, 0.001, 0.01)\n",
        "  # w1 = aq_dl.fit()\n",
        "  w2 = lp_dl.fit()\n",
        "  print(w2)\n",
        "  \n",
        "  # plot_hist(data_pos[:, feat], data_neg[:, feat], feat)\n",
        "  \n",
        "  # model2 = GenerativeLearning(aq_data)\n",
        "  \n",
        "  # w = model2.fit_lda_linear()\n",
        "  # model2.predict(aq_data[:, :-1])\n",
        "  # plot_regression(model2.data[:,feat], model2.y, model2.w, feat)\n",
        "  \n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
